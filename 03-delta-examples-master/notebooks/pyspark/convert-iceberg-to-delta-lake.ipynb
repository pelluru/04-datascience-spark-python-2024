{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dabf1f-038a-4642-ac2d-73bc4b1a6726",
   "metadata": {},
   "source": [
    "# Convert Iceberg to Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1a40f3-0bd6-4eda-b1e7-f92e24cce3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/matthew.powers/opt/miniconda3/envs/pyspark-332-delta-230/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthew.powers/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthew.powers/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "io.delta#delta-iceberg_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.3_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-995f8b4d-9eed-4d8f-8735-c97842e24dc7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound io.delta#delta-iceberg_2.12;2.3.0 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.1.1 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.3_2.12;1.0.0 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-iceberg_2.12/2.3.0/delta-iceberg_2.12-2.3.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-iceberg_2.12;2.3.0!delta-iceberg_2.12.jar (404ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/1.0.0/iceberg-spark-runtime-3.3_2.12-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.iceberg#iceberg-spark-runtime-3.3_2.12;1.0.0!iceberg-spark-runtime-3.3_2.12.jar (7497ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.1.1/scala-collection-compat_2.12-2.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang.modules#scala-collection-compat_2.12;2.1.1!scala-collection-compat_2.12.jar(bundle) (380ms)\n",
      ":: resolution report :: resolve 2121ms :: artifacts dl 8288ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-iceberg_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.3_2.12;1.0.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.1.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-995f8b4d-9eed-4d8f-8735-c97842e24dc7\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 3 already retrieved (24398kB/17ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 13:17:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "from delta import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "testRoot = \"/tmp/delta-iceberg-converter/\"\n",
    "warehousePath = testRoot + \"iceberg_tables\"\n",
    "shutil.rmtree(testRoot, ignore_errors=True)\n",
    "\n",
    "table = \"local.db.table\"\n",
    "tablePath = \"file://\" + warehousePath + \"/db/table\"\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", warehousePath)\n",
    ")\n",
    "\n",
    "my_packages = [\n",
    "    \"io.delta:delta-iceberg_2.12:2.3.0\",\n",
    "    \"org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.0.0\",\n",
    "]\n",
    "\n",
    "spark = configure_spark_with_delta_pip(\n",
    "    builder, extra_packages=my_packages\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf29580d-553c-4652-af51-0bc50a763951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://qtk9h72yp0.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11eeab430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93065ec-d2c1-4709-b6a8-d1d6dae7b6bd",
   "metadata": {},
   "source": [
    "## Create Iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cb9065-f48f-4804-a79a-69020f46cf6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    f\"CREATE TABLE {table} (id BIGINT, data STRING) USING ICEBERG PARTITIONED BY (data)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7678a81-6ca4-4032-8f9a-55d99340f931",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"INSERT INTO {table} VALUES (1, 'a'), (2, 'b')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d013dc-c1fb-4f45-999c-2955d25a26c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"INSERT INTO {table} VALUES (3, 'c')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6900144-02a7-41b4-bf15-13e564051ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  3|   c|\n",
      "|  2|   b|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from local.db.table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "905bd89a-6922-4fa8-ba06-af463353d904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/delta-iceberg-converter/iceberg_tables/db/table/\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   ├── \u001b[01;34mdata=a\u001b[0m\n",
      "│   │   └── \u001b[00m00000-0-fbd8e57f-be89-4fad-9d29-2df71248d789-00001.parquet\u001b[0m\n",
      "│   ├── \u001b[01;34mdata=b\u001b[0m\n",
      "│   │   └── \u001b[00m00001-1-44c83e06-6962-4292-8e46-3f9e47c30d4a-00001.parquet\u001b[0m\n",
      "│   └── \u001b[01;34mdata=c\u001b[0m\n",
      "│       └── \u001b[00m00000-2-36892acb-e25f-41ca-a1e9-7e1495510171-00001.parquet\u001b[0m\n",
      "└── \u001b[01;34mmetadata\u001b[0m\n",
      "    ├── \u001b[00md099f186-c9da-4fb8-8a44-82b1338749a5-m0.avro\u001b[0m\n",
      "    ├── \u001b[00me23838f6-3ddf-47c3-85ad-f6c87b140de9-m0.avro\u001b[0m\n",
      "    ├── \u001b[00msnap-3685361640488939140-1-e23838f6-3ddf-47c3-85ad-f6c87b140de9.avro\u001b[0m\n",
      "    ├── \u001b[00msnap-8632565756425441974-1-d099f186-c9da-4fb8-8a44-82b1338749a5.avro\u001b[0m\n",
      "    ├── \u001b[00mv1.metadata.json\u001b[0m\n",
      "    ├── \u001b[00mv2.metadata.json\u001b[0m\n",
      "    ├── \u001b[00mv3.metadata.json\u001b[0m\n",
      "    └── \u001b[00mversion-hint.text\u001b[0m\n",
      "\n",
      "5 directories, 11 files\n"
     ]
    }
   ],
   "source": [
    "!tree /tmp/delta-iceberg-converter/iceberg_tables/db/table/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bdec8-8fbc-43ca-8ecd-2044f0e6f324",
   "metadata": {},
   "source": [
    "## Convert to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7bf8e0-42de-4ef1-be56-8c63e16d2b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 13:26:17 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CONVERT TO DELTA iceberg.`{tablePath}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24982a43-5d15-4fa4-880b-18641228bfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  2|   b|\n",
      "|  1|   a|\n",
      "|  3|   c|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(tablePath).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4d5af9-535b-49b8-86db-bff47d898090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/delta-iceberg-converter/iceberg_tables/db/table/\u001b[0m\n",
      "├── \u001b[01;34m_delta_log\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000000.checkpoint.parquet\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000000.json\u001b[0m\n",
      "│   └── \u001b[00m_last_checkpoint\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   ├── \u001b[01;34mdata=a\u001b[0m\n",
      "│   │   └── \u001b[00m00000-0-fbd8e57f-be89-4fad-9d29-2df71248d789-00001.parquet\u001b[0m\n",
      "│   ├── \u001b[01;34mdata=b\u001b[0m\n",
      "│   │   └── \u001b[00m00001-1-44c83e06-6962-4292-8e46-3f9e47c30d4a-00001.parquet\u001b[0m\n",
      "│   └── \u001b[01;34mdata=c\u001b[0m\n",
      "│       └── \u001b[00m00000-2-36892acb-e25f-41ca-a1e9-7e1495510171-00001.parquet\u001b[0m\n",
      "└── \u001b[01;34mmetadata\u001b[0m\n",
      "    ├── \u001b[00md099f186-c9da-4fb8-8a44-82b1338749a5-m0.avro\u001b[0m\n",
      "    ├── \u001b[00me23838f6-3ddf-47c3-85ad-f6c87b140de9-m0.avro\u001b[0m\n",
      "    ├── \u001b[00msnap-3685361640488939140-1-e23838f6-3ddf-47c3-85ad-f6c87b140de9.avro\u001b[0m\n",
      "    ├── \u001b[00msnap-8632565756425441974-1-d099f186-c9da-4fb8-8a44-82b1338749a5.avro\u001b[0m\n",
      "    ├── \u001b[00mv1.metadata.json\u001b[0m\n",
      "    ├── \u001b[00mv2.metadata.json\u001b[0m\n",
      "    ├── \u001b[00mv3.metadata.json\u001b[0m\n",
      "    └── \u001b[00mversion-hint.text\u001b[0m\n",
      "\n",
      "6 directories, 14 files\n"
     ]
    }
   ],
   "source": [
    "!tree /tmp/delta-iceberg-converter/iceberg_tables/db/table/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e7d04-821b-45e6-9a99-06f51bc584d8",
   "metadata": {},
   "source": [
    "## Modifying the converted table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bd03252-990d-42b0-a988-f4912a8b8807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"INSERT INTO delta.`{tablePath}` VALUES (4, 'd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b88181-4920-488d-8891-c64d5777a0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  4|   d|\n",
      "|  2|   b|\n",
      "|  1|   a|\n",
      "|  3|   c|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(tablePath).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc57c4-04e9-4779-bfef-ebdfaa3e8745",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create an external catalog table using Delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1f8344-a9fc-462e-837b-39379a64bf44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE TABLE converted_delta_table USING delta LOCATION '{tablePath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0fe5ff4-41f1-4d55-b6a7-13b790603ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  4|   d|\n",
      "|  2|   b|\n",
      "|  1|   a|\n",
      "|  3|   c|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"converted_delta_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a07fde-563d-4482-a511-542d157269e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c000ed9c-eda4-4451-871a-d371f915791b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(testRoot, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark-332-delta-230]",
   "language": "python",
   "name": "conda-env-pyspark-332-delta-230-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
