# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- name: without distinct
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY GROUPING SETS ((brand), (size), ());
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: with distinct
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(distinct sales) FROM items_sold GROUP BY GROUPING SETS ((brand), (size), ());
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, items_sold.sales, flag], aggs: [] }
            └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, items_sold.sales, flag) }
              └─BatchExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
                └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(distinct items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(distinct items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: column pruning
  sql: |
    create table items_sold (c1 int, brand varchar, c2 int, size varchar, c3 int, sales int, c4 int,);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY GROUPING SETS ((size), (brand), ());
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.size_expanded, items_sold.brand_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.size_expanded, items_sold.brand_expanded, flag) }
          └─BatchExpand { column_subsets: [[items_sold.size], [items_sold.brand], []] }
            └─BatchProject { exprs: [items_sold.size, items_sold.brand, items_sold.sales] }
              └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [size, brand, flag], pk_columns: [size, brand, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.size_expanded, items_sold.brand_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.size_expanded, items_sold.brand_expanded, flag) }
          └─StreamExpand { column_subsets: [[items_sold.size], [items_sold.brand], []] }
            └─StreamProject { exprs: [items_sold.size, items_sold.brand, items_sold.sales, items_sold._row_id] }
              └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: grouping agg calls
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales), grouping(brand) g1, grouping(size) g2, grouping(brand,size) g3, count(distinct sales) FROM items_sold GROUP BY GROUPING SETS ((brand), (size), ());
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(sum(items_sold.sales)), Case((0:Int64 = flag), 0:Int32, (1:Int64 = flag), 1:Int32, (2:Int64 = flag), 1:Int32) as $expr1, Case((0:Int64 = flag), 1:Int32, (1:Int64 = flag), 0:Int32, (2:Int64 = flag), 1:Int32) as $expr2, Case((0:Int64 = flag), 1:Int32, (1:Int64 = flag), 2:Int32, (2:Int64 = flag), 3:Int32) as $expr3, count(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(sum(items_sold.sales)), count(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, items_sold.sales, flag], aggs: [sum(items_sold.sales)] }
            └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, items_sold.sales, flag) }
              └─BatchExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
                └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, g1, g2, g3, count, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), Case((0:Int64 = flag), 0:Int32, (1:Int64 = flag), 1:Int32, (2:Int64 = flag), 1:Int32) as $expr1, Case((0:Int64 = flag), 1:Int32, (1:Int64 = flag), 0:Int32, (2:Int64 = flag), 1:Int32) as $expr2, Case((0:Int64 = flag), 1:Int32, (1:Int64 = flag), 2:Int32, (2:Int64 = flag), 3:Int32) as $expr3, count(distinct items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count(distinct items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[items_sold.brand], [items_sold.size], []] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: too many arguments for grouping error
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales), grouping(brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, brand, size, size) FROM items_sold GROUP BY GROUPING SETS ((brand), (size), ());
  planner_error: 'Invalid input syntax: GROUPING must have fewer than 32 arguments'
- name: currently not support using grouping in query without grouping sets.
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales), grouping(size) FROM items_sold GROUP BY brand, size;
  planner_error: |-
    Not supported: GROUPING must be used in a query with grouping sets
    HINT: try to use grouping sets instead
- name: rollup1
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY ROLLUP(brand, size);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[], [items_sold.brand], [items_sold.brand, items_sold.size]] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[], [items_sold.brand], [items_sold.brand, items_sold.size]] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: rollup2
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY ROLLUP((brand, size));
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[], [items_sold.brand, items_sold.size]] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[], [items_sold.brand, items_sold.size]] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: cube1
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY CUBE(brand, size);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[], [items_sold.brand], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[], [items_sold.brand], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: cube2
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY CUBE(brand, size, size);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[], [items_sold.brand], [items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size], [items_sold.brand, items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[], [items_sold.brand], [items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size], [items_sold.brand, items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: cube3
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, size, sum(sales) FROM items_sold GROUP BY CUBE((brand, size), size);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales)] }
      └─BatchHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─BatchExpand { column_subsets: [[], [items_sold.brand, items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, size, sum, flag(hidden)], stream_key: [brand, size, flag], pk_columns: [brand, size, flag], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand_expanded, items_sold.size_expanded, sum(items_sold.sales), flag] }
      └─StreamHashAgg { group_key: [items_sold.brand_expanded, items_sold.size_expanded, flag], aggs: [sum(items_sold.sales), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand_expanded, items_sold.size_expanded, flag) }
          └─StreamExpand { column_subsets: [[], [items_sold.brand, items_sold.size], [items_sold.size], [items_sold.brand, items_sold.size]] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold.size, items_sold.sales, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
- name: only one set in grouping sets
  sql: |
    create table items_sold (brand varchar, size varchar, sales int);
    SELECT brand, sum(sales) FROM items_sold GROUP BY GROUPING SETS(brand);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [items_sold.brand, sum(null:Int32)] }
      └─BatchHashAgg { group_key: [items_sold.brand, 0:Int64], aggs: [sum(null:Int32)] }
        └─BatchExchange { order: [], dist: HashShard(items_sold.brand, 0:Int64) }
          └─BatchProject { exprs: [items_sold.brand, null:Int32, 0:Int64] }
            └─BatchScan { table: items_sold, columns: [items_sold.brand], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [brand, sum, 0:Int64(hidden)], stream_key: [brand, 0:Int64], pk_columns: [brand, 0:Int64], pk_conflict: NoCheck }
    └─StreamProject { exprs: [items_sold.brand, sum(null:Int32), 0:Int64] }
      └─StreamHashAgg { group_key: [items_sold.brand, 0:Int64], aggs: [sum(null:Int32), count] }
        └─StreamExchange { dist: HashShard(items_sold.brand, 0:Int64) }
          └─StreamProject { exprs: [items_sold.brand, null:Int32, 0:Int64, items_sold._row_id] }
            └─StreamTableScan { table: items_sold, columns: [items_sold.brand, items_sold._row_id], stream_scan_type: ArrangementBackfill, stream_key: [items_sold._row_id], pk: [_row_id], dist: UpstreamHashShard(items_sold._row_id) }
