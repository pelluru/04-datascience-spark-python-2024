{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "This time we will create our own dataset with fictional numbers to describe a house market. As we are going to create random data don't try to reason of the numbers.\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>housing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x120c5f880>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('housing').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create 3 differents Series, each of length 100, as follows: \n",
    "1. The first a random number from 1 to 4 \n",
    "2. The second a random number from 1 to 3\n",
    "3. The third a random number from 10,000 to 30,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 1, 3, 4, 4, 3, 3, 2, 4, 1, 2, 1, 1, 3, 3, 3, 4, 3, 4, 2, 1, 4, 1, 2, 2, 1, 3, 2, 3, 3, 4, 2, 2, 4, 4, 4, 1, 3, 3, 3, 4, 3, 1, 2, 2, 3, 1, 2, 2, 4, 4, 2, 4, 2, 4, 4, 1, 2, 2, 2, 1, 4, 2, 2, 1, 2, 4, 1, 2, 2, 3, 1, 3, 2, 4, 2, 2, 2, 2, 3, 4, 3, 1, 2, 3, 2, 1, 4, 3, 1, 3, 3, 1, 1, 1, 4, 2, 1]\n",
      "<class 'list'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "r1 = list(map(int, list(np.random.randint(low=1, high=5, size=100))))\n",
    "print(r1)\n",
    "print(type(r1))\n",
    "print(type(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 2, 2, 2, 1, 3, 2, 2, 3, 2, 1, 3, 1, 3, 1, 2, 2, 1, 1, 3, 3, 2, 1, 3, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 2, 2, 1, 3, 1, 1, 1, 3, 2, 3, 2, 2, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 1, 1, 2, 1, 1, 3, 3, 3, 2, 2, 2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2]\n",
      "<class 'list'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "r2 = list(map(int, list(np.random.randint(low=1, high=4, size=100))))\n",
    "print(r2)\n",
    "print(type(r2))\n",
    "print(type(r2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19251, 20692, 28636, 11382, 17866, 16892, 11944, 26508, 21078, 17809, 16348, 11326, 21235, 26700, 16368, 18024, 12547, 14566, 19052, 13310, 17871, 25421, 18148, 13638, 22001, 13197, 10803, 20837, 17731, 27969, 13459, 22946, 24510, 14241, 25259, 13106, 23615, 12339, 18435, 20183, 27219, 23620, 29376, 15957, 16831, 23508, 26873, 17767, 20840, 12765, 25270, 28943, 17316, 17740, 21886, 18154, 18395, 21238, 16141, 25060, 20948, 10765, 10428, 15302, 25465, 22898, 17043, 28342, 22550, 18083, 16694, 20149, 29526, 12389, 28817, 18420, 20989, 19624, 20608, 10605, 22838, 22324, 25118, 24155, 24100, 17965, 20427, 19085, 21422, 28444, 11810, 17682, 12890, 28848, 18079, 22207, 12062, 20965, 29665, 13117]\n",
      "<class 'list'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "r3 = list(map(int, list(np.random.randint(low=10000, high=30001, size=100))))\n",
    "print(r3)\n",
    "print(type(r3))\n",
    "print(type(r3[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Let's create a DataFrame by joinning the Series by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tring to find an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(r1, r2, r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(R1=2, R2=1, R3=19251), Row(R1=3, R2=3, R3=20692)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# giving column names of dataframe\n",
    "columns = [\"R1\", \"R2\", \"R3\"]\n",
    "  \n",
    "# creating a dataframe\n",
    "dataframe = spark.createDataFrame(data, columns)\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+\n",
      "| R1| R2|   R3|\n",
      "+---+---+-----+\n",
      "|  2|  1|19251|\n",
      "|  3|  3|20692|\n",
      "|  1|  1|28636|\n",
      "|  1|  2|11382|\n",
      "|  3|  2|17866|\n",
      "+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Change the name of the columns to bedrs, bathrs, price_sqr_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------------+\n",
      "|bedrs|bathrs|price_sqr_meter|\n",
      "+-----+------+---------------+\n",
      "|    2|     1|          19251|\n",
      "|    3|     3|          20692|\n",
      "+-----+------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe = dataframe.withColumnRenamed([\"R1\",\"R2\",\"R3\"],[\"bedrs\",\"bathrs\",\"price_sqr_meter\"])\n",
    "dataframe = dataframe.withColumnRenamed('R1','bedrs').withColumnRenamed('R2', 'bathrs').withColumnRenamed('R3', 'price_sqr_meter')\n",
    "\n",
    "dataframe.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bedrs: long (nullable = true)\n",
      " |-- bathrs: long (nullable = true)\n",
      " |-- price_sqr_meter: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Create a one column DataFrame with the values of the 3 Series and assign it to 'bigcolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "bigColumn = []\n",
    "bigColumn.extend(r1)\n",
    "print(len(bigColumn))\n",
    "\n",
    "bigColumn.extend(r2)\n",
    "print(len(bigColumn))\n",
    "\n",
    "bigColumn.extend(r3)\n",
    "print(len(bigColumn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 1, 3, 4, 4, 3, 3, 2, 4, 1, 2, 1, 1, 3, 3, 3, 4, 3, 4, 2, 1, 4, 1, 2, 2, 1, 3, 2, 3, 3, 4, 2, 2, 4, 4, 4, 1, 3, 3, 3, 4, 3, 1, 2, 2, 3, 1, 2, 2, 4, 4, 2, 4, 2, 4, 4, 1, 2, 2, 2, 1, 4, 2, 2, 1, 2, 4, 1, 2, 2, 3, 1, 3, 2, 4, 2, 2, 2, 2, 3, 4, 3, 1, 2, 3, 2, 1, 4, 3, 1, 3, 3, 1, 1, 1, 4, 2, 1, 1, 3, 1, 2, 2, 2, 1, 3, 2, 2, 3, 2, 1, 3, 1, 3, 1, 2, 2, 1, 1, 3, 3, 2, 1, 3, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 2, 2, 1, 3, 1, 1, 1, 3, 2, 3, 2, 2, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 1, 1, 2, 1, 1, 3, 3, 3, 2, 2, 2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 19251, 20692, 28636, 11382, 17866, 16892, 11944, 26508, 21078, 17809, 16348, 11326, 21235, 26700, 16368, 18024, 12547, 14566, 19052, 13310, 17871, 25421, 18148, 13638, 22001, 13197, 10803, 20837, 17731, 27969, 13459, 22946, 24510, 14241, 25259, 13106, 23615, 12339, 18435, 20183, 27219, 23620, 29376, 15957, 16831, 23508, 26873, 17767, 20840, 12765, 25270, 28943, 17316, 17740, 21886, 18154, 18395, 21238, 16141, 25060, 20948, 10765, 10428, 15302, 25465, 22898, 17043, 28342, 22550, 18083, 16694, 20149, 29526, 12389, 28817, 18420, 20989, 19624, 20608, 10605, 22838, 22324, 25118, 24155, 24100, 17965, 20427, 19085, 21422, 28444, 11810, 17682, 12890, 28848, 18079, 22207, 12062, 20965, 29665, 13117]\n"
     ]
    }
   ],
   "source": [
    "print(bigColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(values=2), Row(values=3)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data = list(zip(bigColumn))\n",
    "column = ['values']\n",
    "bigColumnDF = spark.createDataFrame(big_data, column)\n",
    "bigColumnDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|values|\n",
      "+------+\n",
      "|     2|\n",
      "|     3|\n",
      "|     1|\n",
      "|     1|\n",
      "|     3|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigColumnDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Oops, it seems it is going only until index 99. Is it true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(bigColumnDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Reindex the DataFrame so it goes from 0 to 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
